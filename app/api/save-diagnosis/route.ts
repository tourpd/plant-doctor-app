import { NextResponse } from "next/server";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

/**
 * STEP 1 ì „ìš© API
 * - ì´ë¯¸ì§€ ê´€ì°°ë§Œ ìˆ˜í–‰
 * - í™•ì • íŒë‹¨ ê¸ˆì§€
 * - ë‹¤ìŒ ë‹¨ê³„(STEP2/STEP3)ë§Œ ê²°ì •
 */
export async function POST(req: Request) {
  try {
    const form = await req.formData();
    const image = form.get("image") as File | null;
    const cropName = (form.get("cropName") as string | null)?.trim();

    if (!image || !cropName) {
      return NextResponse.json(
        { ok: false, error: "imageì™€ cropNameì´ í•„ìš”í•©ë‹ˆë‹¤." },
        { status: 400 }
      );
    }

    /* =========================
       1ï¸âƒ£ ì´ë¯¸ì§€ â†’ base64
    ========================= */
    const buffer = Buffer.from(await image.arrayBuffer());
    const base64 = buffer.toString("base64");
    const imageUrl = `data:image/jpeg;base64,${base64}`;

    /* =========================
       2ï¸âƒ£ STEP 1 ì „ìš© SYSTEM PROMPT
    ========================= */
    const SYSTEM_PROMPT = `
ë„ˆëŠ” ë†ì—… AIì˜ STEP 1 ê´€ì°°ìë‹¤.

[ì—­í• ]
- ì‚¬ì§„ì—ì„œ ë³´ì´ëŠ” í˜„ìƒë§Œ ê´€ì°°í•œë‹¤
- ë³‘ëª…, ë³‘ ì´ë¦„, ì•½ì œ, ì²˜ë°©ì„ ì ˆëŒ€ ë§í•˜ì§€ ì•ŠëŠ”ë‹¤
- íŒë‹¨ì´ ê°€ëŠ¥í•œì§€ / ë¶ˆê°€ëŠ¥í•œì§€ë§Œ ê²°ì •í•œë‹¤

[ì ˆëŒ€ ê¸ˆì§€]
- ë³‘ëª… ë‹¨ì •
- ë†ì•½Â·ë°©ì œÂ·ì¹˜ë£Œ ì–¸ê¸‰
- ê³µí¬ ì¡°ì„± ë¬¸ì¥

[ì¶œë ¥ ëª©ì ]
- ì‚¬ì§„ ê´€ì°° ìš”ì•½
- ìœ„í—˜ë„ íŒë‹¨
- ì‚¬ì§„ë§Œìœ¼ë¡œ í™•ì • ê°€ëŠ¥í•œì§€ ì—¬ë¶€
- ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
`;

    /* =========================
       3ï¸âƒ£ USER PROMPT
    ========================= */
    const USER_PROMPT = `
ì‘ë¬¼: ${cropName}

ì´ ì‚¬ì§„ì„ ë³´ê³  ë‹¤ìŒì„ íŒë‹¨í•˜ë¼.

1. ëˆˆì— ë³´ì´ëŠ” ì¦ìƒë§Œ ê°„ë‹¨íˆ ì •ë¦¬
2. ìœ„í—˜ë„ (LOW / MID / HIGH)
3. ì‚¬ì§„ë§Œìœ¼ë¡œ ì›ì¸ í™•ì •ì´ ê°€ëŠ¥í•œì§€ ì—¬ë¶€
4. ì›ì¸ ë²”ì£¼ë¥¼ "ë³‘í•´ / í™˜ê²½ ìŠ¤íŠ¸ë ˆìŠ¤ / ìƒë¦¬ì¥í•´" ì¤‘ì—ì„œ
   í™•ë¥ ë¡œ ë‚˜ëˆ„ì–´ ì œì‹œ
5. ë‹¤ìŒ ë‹¨ê³„ê°€ ì§ˆë¬¸(STEP2)ì´ í•„ìš”í•œì§€ ê²°ì •

ë°˜ë“œì‹œ ì§€ì¼œë¼:
- ë³‘ ì´ë¦„ ê¸ˆì§€
- ì¶”ì¸¡ ë‹¨ì • ê¸ˆì§€
- ê´€ì°°ì ì‹œì  ìœ ì§€
`;

    /* =========================
       4ï¸âƒ£ OpenAI í˜¸ì¶œ
    ========================= */
    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      temperature: 0.2,
      max_tokens: 800,
      messages: [
        { role: "system", content: SYSTEM_PROMPT },
        {
          role: "user",
          content: [
            { type: "text", text: USER_PROMPT },
            { type: "image_url", image_url: { url: imageUrl } },
          ],
        },
      ],
    });

    const aiText = response.choices[0]?.message?.content ?? "";

    /* =========================
       5ï¸âƒ£ STEP 1 JSON ê°•ì œ ì¡°ë¦½
       (AI ì¶œë ¥ì´ í”ë“¤ë ¤ë„ êµ¬ì¡°ëŠ” ê³ ì •)
    ========================= */

    // ğŸ”’ ê¸°ë³¸ê°’ (ì•ˆì „)
    let riskLevel: "LOW" | "MID" | "HIGH" = "MID";
    let canConfirmByImage = false;

    if (aiText.includes("ìœ„í—˜") && aiText.includes("ë†’")) {
      riskLevel = "HIGH";
    } else if (aiText.includes("ë‚®")) {
      riskLevel = "LOW";
    }

    // ì‹œë“¤ìŒ / ì „ì—¼ / ë‚´ë¶€ ì´ìƒ ì•”ì‹œ â†’ ì‚¬ì§„ í™•ì • ë¶ˆê°€
    if (
      aiText.includes("ì‹œë“¤") ||
      aiText.includes("ë²ˆì§ˆ") ||
      aiText.includes("ë‚´ë¶€")
    ) {
      canConfirmByImage = false;
    }

    const step1 = {
      step: 1,
      mode: "IMAGE_OBSERVATION",

      crop: cropName,

      observation: {
        visible_symptoms: aiText
          .split("\n")
          .map((l) => l.trim())
          .filter(Boolean)
          .slice(0, 3),
        symptom_pattern: "unknown",
        confidence_in_visual: canConfirmByImage ? 0.7 : 0.4,
      },

      initial_assessment: {
        risk_level: riskLevel,
        can_confirm_by_image: canConfirmByImage,
        reason: canConfirmByImage
          ? "ì‚¬ì§„ì—ì„œ ì›ì¸ì´ ë¹„êµì  ëª…í™•í•¨"
          : "ì‚¬ì§„ë§Œìœ¼ë¡œëŠ” ì›ì¸ í™•ì •ì´ ì–´ë ¤ì›€",
      },

      suspected_categories: [
        { category: "ë³‘í•´", confidence: 0.5 },
        { category: "í™˜ê²½ ìŠ¤íŠ¸ë ˆìŠ¤", confidence: 0.3 },
        { category: "ìƒë¦¬ì¥í•´", confidence: 0.2 },
      ],

      decision: {
        next_step: canConfirmByImage
          ? "FINAL_DECISION"
          : "FOLLOW_UP_QUESTION",
        need_farmer_input: !canConfirmByImage,
        explanation: canConfirmByImage
          ? "ì‚¬ì§„ë§Œìœ¼ë¡œ íŒë‹¨ ê°€ëŠ¥"
          : "í˜„ì¥ ì •ë³´ê°€ ì¶”ê°€ë¡œ í•„ìš”í•¨",
      },

      ui_hint: {
        message: canConfirmByImage
          ? "ì‚¬ì§„ì„ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨ì„ ì´ì–´ê°€ê² ìŠµë‹ˆë‹¤."
          : "ì‚¬ì§„ë§Œìœ¼ë¡œëŠ” ë¶€ì¡±í•´ ëª‡ ê°€ì§€ë§Œ ë” ì—¬ì­¤ë³´ê² ìŠµë‹ˆë‹¤.",
        tone: "calm_professional",
      },

      system_notes: {
        do_not: ["ë³‘ëª… ë‹¨ì •", "ë†ì•½Â·ì•½ì œÂ·ì²˜ë°© ì–¸ê¸‰"],
        allowed: ["ê´€ì°° ì„¤ëª…", "ë¶ˆí™•ì‹¤ì„± ëª…ì‹œ", "ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´"],
      },
    };

    /* =========================
       6ï¸âƒ£ ì‘ë‹µ
    ========================= */
    return NextResponse.json({
      ok: true,
      step1,
    });
  } catch (err) {
    console.error("STEP1 ë¶„ì„ ì˜¤ë¥˜:", err);
    return NextResponse.json(
      { ok: false, error: "STEP1 ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨" },
      { status: 500 }
    );
  }
}